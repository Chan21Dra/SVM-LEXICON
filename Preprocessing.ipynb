{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. FILTERING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File DATASET/DEBAT1_CAPRES01.csv telah diproses: 0 baris dihapus\n",
      "Tersimpan di: Proses/FilterDEBAT1_CAPRES01.csv\n",
      "File DATASET/DEBAT5_CAPRES01.csv telah diproses: 766 baris dihapus\n",
      "Tersimpan di: Proses/FilterDEBAT5_CAPRES01.csv\n",
      "File DATASET/DEBAT1_CAPRES02.csv telah diproses: 517 baris dihapus\n",
      "Tersimpan di: Proses/FilterDEBAT1_CAPRES02.csv\n",
      "File DATASET/DEBAT5_CAPRES02.csv telah diproses: 444 baris dihapus\n",
      "Tersimpan di: Proses/FilterDEBAT5_CAPRES02.csv\n",
      "File DATASET/DEBAT1_CAPRES03.csv telah diproses: 502 baris dihapus\n",
      "Tersimpan di: Proses/FilterDEBAT1_CAPRES03.csv\n",
      "File DATASET/DEBAT5_CAPRES03.csv telah diproses: 449 baris dihapus\n",
      "Tersimpan di: Proses/FilterDEBAT5_CAPRES03.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Buat direktori Proses jika belum ada\n",
    "direktori_output = \"Proses\"\n",
    "if not os.path.exists(direktori_output):\n",
    "    os.makedirs(direktori_output)\n",
    "\n",
    "def bersihkan_csv(nama_file):\n",
    "    # Baca file CSV\n",
    "    df = pd.read_csv(nama_file)\n",
    "    \n",
    "    # Buat mask untuk baris yang akan disimpan\n",
    "    mask = (df['lang'].str.lower().str.contains('in', na=False) |\n",
    "            df['location'].str.lower().str.contains('indonesia', na=False))\n",
    "    \n",
    "    # Simpan hanya baris yang sesuai kriteria\n",
    "    df_bersih = df[mask].copy()\n",
    "    \n",
    "    # Reset index\n",
    "    df_bersih.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Buat nama file output\n",
    "    nama_dasar = os.path.basename(nama_file)\n",
    "    path_output = os.path.join(direktori_output, f\"Filter{nama_dasar}\")\n",
    "    \n",
    "    # Simpan ke CSV baru\n",
    "    df_bersih.to_csv(path_output, index=False)\n",
    "    return len(df) - len(df_bersih)\n",
    "\n",
    "# Daftar file yang akan diproses\n",
    "file_input = [\n",
    "    \"DATASET/DEBAT1_CAPRES01.csv\",\n",
    "    \"DATASET/DEBAT5_CAPRES01.csv\",\n",
    "    \"DATASET/DEBAT1_CAPRES02.csv\",\n",
    "    \"DATASET/DEBAT5_CAPRES02.csv\",\n",
    "    \"DATASET/DEBAT1_CAPRES03.csv\",\n",
    "    \"DATASET/DEBAT5_CAPRES03.csv\"\n",
    "]\n",
    "\n",
    "# Proses setiap file\n",
    "for file in file_input:\n",
    "    try:\n",
    "        baris_terhapus = bersihkan_csv(file)\n",
    "        print(f'File {file} telah diproses: {baris_terhapus} baris dihapus')\n",
    "        print(f'Tersimpan di: {direktori_output}/Filter{os.path.basename(file)}')\n",
    "    except Exception as e:\n",
    "        print(f'Terjadi kesalahan saat memproses {file}: {str(e)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. GABUNGKAN FILE UNTUK SELANJUTNYA DILAKUKAN PREPROCESSING\n",
    "    \n",
    "    Sebelum digabungkan, akan diberikan kolom baru sebagai penanda yang memisahkan data tersebut untuk paslon keberapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. PENANDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berhasil menambahkan kolom Paslon=Anies pada Proses/FilterDEBAT1_CAPRES01.csv\n",
      "Total 1954 baris diperbarui\n",
      "Berhasil menambahkan kolom Debat=Debat 1 pada Proses/FilterDEBAT1_CAPRES01.csv\n",
      "Total 1954 baris diperbarui\n",
      "Berhasil menambahkan kolom Paslon=Anies pada Proses/FilterDEBAT5_CAPRES01.csv\n",
      "Total 865 baris diperbarui\n",
      "Berhasil menambahkan kolom Debat=Debat 5 pada Proses/FilterDEBAT5_CAPRES01.csv\n",
      "Total 865 baris diperbarui\n",
      "Berhasil menambahkan kolom Paslon=Prabowo pada Proses/FilterDEBAT1_CAPRES02.csv\n",
      "Total 1202 baris diperbarui\n",
      "Berhasil menambahkan kolom Debat=Debat 1 pada Proses/FilterDEBAT1_CAPRES02.csv\n",
      "Total 1202 baris diperbarui\n",
      "Berhasil menambahkan kolom Paslon=Prabowo pada Proses/FilterDEBAT5_CAPRES02.csv\n",
      "Total 1294 baris diperbarui\n",
      "Berhasil menambahkan kolom Debat=Debat 5 pada Proses/FilterDEBAT5_CAPRES02.csv\n",
      "Total 1294 baris diperbarui\n",
      "Berhasil menambahkan kolom Paslon=Ganjar pada Proses/FilterDEBAT1_CAPRES03.csv\n",
      "Total 535 baris diperbarui\n",
      "Berhasil menambahkan kolom Debat=Debat 1 pada Proses/FilterDEBAT1_CAPRES03.csv\n",
      "Total 535 baris diperbarui\n",
      "Berhasil menambahkan kolom Paslon=Ganjar pada Proses/FilterDEBAT5_CAPRES03.csv\n",
      "Total 731 baris diperbarui\n",
      "Berhasil menambahkan kolom Debat=Debat 5 pada Proses/FilterDEBAT5_CAPRES03.csv\n",
      "Total 731 baris diperbarui\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_paslon_column(input_path, paslon_name):\n",
    "    # Baca CSV\n",
    "    df = pd.read_csv(input_path)\n",
    "    \n",
    "    # Tambah kolom Paslon dengan nilai yang sama untuk semua baris\n",
    "    df['Paslon'] = paslon_name\n",
    "    \n",
    "    # Simpan kembali ke file yang sama\n",
    "    df.to_csv(input_path, index=False)\n",
    "    \n",
    "    return len(df)\n",
    "\n",
    "def add_debat_column(input_path, debat_name):\n",
    "    # Baca CSV\n",
    "    df = pd.read_csv(input_path)\n",
    "    \n",
    "    # Tambah kolom Debat dengan nilai yang sama untuk semua baris\n",
    "    df['Debat'] = debat_name\n",
    "    \n",
    "    # Simpan kembali ke file yang sama\n",
    "    df.to_csv(input_path, index=False)\n",
    "    \n",
    "    return len(df)\n",
    "\n",
    "def main():\n",
    "    # Definisi file input dan nilai paslon serta debat\n",
    "    files_config = {\n",
    "        'Proses/FilterDEBAT1_CAPRES01.csv': ('Anies', 'Debat 1'),\n",
    "        'Proses/FilterDEBAT5_CAPRES01.csv': ('Anies', 'Debat 5'),\n",
    "        'Proses/FilterDEBAT1_CAPRES02.csv': ('Prabowo', 'Debat 1'),\n",
    "        'Proses/FilterDEBAT5_CAPRES02.csv': ('Prabowo', 'Debat 5'),\n",
    "        'Proses/FilterDEBAT1_CAPRES03.csv': ('Ganjar', 'Debat 1'),\n",
    "        'Proses/FilterDEBAT5_CAPRES03.csv': ('Ganjar', 'Debat 5')\n",
    "    }\n",
    "    \n",
    "    for file_path, (paslon, debat) in files_config.items():\n",
    "        try:\n",
    "            rows = add_paslon_column(file_path, paslon)\n",
    "            print(f'Berhasil menambahkan kolom Paslon={paslon} pada {file_path}')\n",
    "            print(f'Total {rows} baris diperbarui')\n",
    "            \n",
    "            rows = add_debat_column(file_path, debat)\n",
    "            print(f'Berhasil menambahkan kolom Debat={debat} pada {file_path}')\n",
    "            print(f'Total {rows} baris diperbarui')\n",
    "        except Exception as e:\n",
    "            print(f'Error saat memproses {file_path}: {str(e)}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. PENGGABUNGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penggabungan selesai: 6581 baris data tersimpan di DATA_DEBAT_TOTAL.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def merge_csv_files():\n",
    "    # Daftar file yang akan digabung\n",
    "    files = [\n",
    "        'Proses/FilterDEBAT1_CAPRES01.csv',\n",
    "        'Proses/FilterDEBAT1_CAPRES02.csv',\n",
    "        'Proses/FilterDEBAT1_CAPRES03.csv',\n",
    "        'Proses/FilterDEBAT5_CAPRES01.csv',\n",
    "        'Proses/FilterDEBAT5_CAPRES02.csv',\n",
    "        'Proses/FilterDEBAT5_CAPRES03.csv',\n",
    "    ]\n",
    "    \n",
    "    # List untuk menyimpan DataFrame\n",
    "    all_data = []\n",
    "    \n",
    "    # Baca dan gabungkan semua file\n",
    "    for file in files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            all_data.append(df)\n",
    "        except Exception as e:\n",
    "            print(f'Error membaca file {file}: {str(e)}')\n",
    "            continue\n",
    "    \n",
    "    # Gabungkan semua DataFrame\n",
    "    merged_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Simpan hasil gabungan\n",
    "    output_path = 'Proses/DATA_DEBAT_TOTAL.csv'\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    return len(merged_df)\n",
    "\n",
    "# Jalankan penggabungan\n",
    "total_rows = merge_csv_files()\n",
    "print(f'Penggabungan selesai: {total_rows} baris data tersimpan di DATA_DEBAT_TOTAL.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. TAHAP PREPROCESSING\n",
    "\n",
    "    Pada tahap ini akan dilakukan preprocessing sebanyak 7 kali untuk file yang telah digabungkan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. CLEAN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean data selesai dan tersimpan di kolom Clean\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Hapus URL\n",
    "        text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "        \n",
    "        # Hapus mention (@user)\n",
    "        text = re.sub(r'@\\w+', '', text)\n",
    "        \n",
    "        # Hapus hashtag (#)\n",
    "        text = re.sub(r'#\\w+', '', text)\n",
    "        \n",
    "        # Hapus RT dan FAV\n",
    "        text = re.sub(r'RT|FAV', '', text)\n",
    "        \n",
    "        # Hapus simbol dan tanda baca\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        \n",
    "        # Hapus angka\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        \n",
    "        # Hapus multiple whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        # Convert ke lowercase\n",
    "        text = text.lower().strip()\n",
    "        \n",
    "        return text\n",
    "    return ''\n",
    "\n",
    "def main():\n",
    "    # Baca file CSV\n",
    "    df = pd.read_csv('Proses/DATA_DEBAT_TOTAL.csv')\n",
    "    \n",
    "    # Bersihkan teks pada kolom 'full_text'\n",
    "    df['Clean'] = df['full_text'].apply(clean_text)\n",
    "    \n",
    "    # Simpan hasil\n",
    "    df.to_csv('Proses/DATA_DEBAT_TOTAL.csv', index=False)\n",
    "    print('Clean data selesai dan tersimpan di kolom Clean')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. TOKENIZING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\olgab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenisasi selesai dan tersimpan di kolom Tokens\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "def tokenize_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Tokenisasi teks\n",
    "        tokens = word_tokenize(text)\n",
    "        return tokens\n",
    "    return []\n",
    "def main():\n",
    "    # Baca file CSV\n",
    "    df = pd.read_csv('Proses/DATA_DEBAT_TOTAL.csv')\n",
    "    \n",
    "    # Tokenisasi teks dari kolom 'Clean'\n",
    "    df['Tokens'] = df['Clean'].apply(tokenize_text)\n",
    "    \n",
    "    # Simpan hasil\n",
    "    df.to_csv('Proses/DATA_DEBAT_TOTAL.csv', index=False)\n",
    "    print('Tokenisasi selesai dan tersimpan di kolom Tokens')\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3. NORMALISASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisasi selesai dan tersimpan di kolom Normalized\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "def normalize_text(tokens):\n",
    "    if isinstance(tokens, list):\n",
    "        # Inisialisasi stemmer\n",
    "        stemmer_factory = StemmerFactory()\n",
    "        stemmer = stemmer_factory.create_stemmer()\n",
    "        \n",
    "        # Stemming setiap token\n",
    "        normalized_tokens = [stemmer.stem(word) for word in tokens]\n",
    "        \n",
    "        return normalized_tokens\n",
    "    return []\n",
    "def main():\n",
    "    # Baca file CSV\n",
    "    df = pd.read_csv('Proses/DATA_DEBAT_TOTAL.csv')\n",
    "    \n",
    "    # Normalisasi tokens\n",
    "    df['Normalized'] = df['Tokens'].apply(eval).apply(normalize_text)\n",
    "    \n",
    "    # Simpan hasil\n",
    "    df.to_csv('Proses/DATA_DEBAT_TOTAL.csv', index=False)\n",
    "    print('Normalisasi selesai dan tersimpan di kolom Normalized')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4. STOPWORD REMOVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopword removal selesai dan tersimpan di kolom Stopword\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    if isinstance(tokens, list):\n",
    "        # Get Indonesian stopwords\n",
    "        stop_factory = StopWordRemoverFactory()\n",
    "        stopwords = stop_factory.get_stop_words()\n",
    "        \n",
    "        # Remove stopwords from tokens\n",
    "        tokens_without_stopwords = [word for word in tokens if word not in stopwords]\n",
    "        \n",
    "        return tokens_without_stopwords\n",
    "    return []\n",
    "def main():\n",
    "    # Read CSV\n",
    "    df = pd.read_csv('Proses/DATA_DEBAT_TOTAL.csv')\n",
    "    \n",
    "    # Remove stopwords from normalized tokens\n",
    "    df['Stopword'] = df['Normalized'].apply(eval).apply(remove_stopwords)\n",
    "    \n",
    "    # Save results\n",
    "    df.to_csv('Proses/DATA_DEBAT_TOTAL.csv', index=False)\n",
    "    print('Stopword removal selesai dan tersimpan di kolom Stopword')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5. STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming selesai dan tersimpan di kolom Stemming\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "def stem_words(tokens):\n",
    "    if isinstance(tokens, list):\n",
    "        # Initialize Sastrawi stemmer\n",
    "        factory = StemmerFactory()\n",
    "        stemmer = factory.create_stemmer()\n",
    "        \n",
    "        # Stem each token\n",
    "        stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "        \n",
    "        return stemmed_tokens\n",
    "    return []\n",
    "\n",
    "def main():\n",
    "    # Read CSV\n",
    "    df = pd.read_csv('Proses/DATA_DEBAT_TOTAL.csv')\n",
    "    \n",
    "    # Apply stemming to tokens after stopword removal\n",
    "    df['Stemming'] = df['Stopword'].apply(eval).apply(stem_words)\n",
    "    \n",
    "    # Save results\n",
    "    df.to_csv('Proses/DATA_DEBAT_TOTAL.csv', index=False)\n",
    "    print('Stemming selesai dan tersimpan di kolom Stemming')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 15\n",
      "Column names: Index(['conversation_id_str', 'created_at', 'favorite_count', 'full_text',\n",
      "       'id_str', 'image_url', 'in_reply_to_screen_name', 'lang', 'location',\n",
      "       'quote_count', 'reply_count', 'retweet_count', 'tweet_url',\n",
      "       'user_id_str', 'username'],\n",
      "      dtype='object')\n",
      "                                              full_text lang      location\n",
      "1750  VIDEO: Cak Imin Serang Balik Prabowo: Emang Et...   in     Indonesia\n",
      "409   @gadisberjilbabb @aniesbaswedan Pemimpin itu K...   in     Indonesia\n",
      "950   @ekky1995 Kalau Prabowo Gibran yg menang surve...   in  di hati kamu\n",
      "227   Kembali kepada mata panda sebab asyik tidur la...   in           NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('Dataset/DEBAT1_CAPRES01.csv')\n",
    "\n",
    "# Print the number of columns and their names\n",
    "print(\"Number of columns:\", len(df.columns))\n",
    "print(\"Column names:\", df.columns)\n",
    "\n",
    "# Display data for 'full_text' and 2 other columns (replace 'other_column1' and 'other_column2' with actual column names)\n",
    "columns_to_display = ['full_text', 'lang', 'location']\n",
    "print(df[columns_to_display].sample(4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
